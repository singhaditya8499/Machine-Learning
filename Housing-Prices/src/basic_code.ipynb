{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74e783b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "91ec59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "06b63e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0.98765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561</td>\n",
       "      <td>6.980</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.0980</td>\n",
       "      <td>3</td>\n",
       "      <td>320</td>\n",
       "      <td>23.0</td>\n",
       "      <td>396.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0.23456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561</td>\n",
       "      <td>6.980</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.6540</td>\n",
       "      <td>3</td>\n",
       "      <td>320</td>\n",
       "      <td>23.0</td>\n",
       "      <td>343.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.44433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561</td>\n",
       "      <td>6.123</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2.9870</td>\n",
       "      <td>3</td>\n",
       "      <td>320</td>\n",
       "      <td>23.0</td>\n",
       "      <td>343.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>0.77763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561</td>\n",
       "      <td>6.222</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.5430</td>\n",
       "      <td>3</td>\n",
       "      <td>329</td>\n",
       "      <td>23.0</td>\n",
       "      <td>343.00</td>\n",
       "      <td>76.00</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.65432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561</td>\n",
       "      <td>6.760</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.9870</td>\n",
       "      <td>3</td>\n",
       "      <td>345</td>\n",
       "      <td>23.0</td>\n",
       "      <td>321.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>511 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "506  0.98765   0.0  12.50     0  0.561  6.980  89.0  2.0980    3  320   \n",
       "507  0.23456   0.0  12.50     0  0.561  6.980  76.0  2.6540    3  320   \n",
       "508  0.44433   0.0  12.50     0  0.561  6.123  98.0  2.9870    3  320   \n",
       "509  0.77763   0.0  12.70     0  0.561  6.222  34.0  2.5430    3  329   \n",
       "510  0.65432   0.0  12.80     0  0.561  6.760  67.0  2.9870    3  345   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "506     23.0  396.00  12.00  12.0  \n",
       "507     23.0  343.00  25.00  32.0  \n",
       "508     23.0  343.00  21.00  54.0  \n",
       "509     23.0  343.00  76.00  67.0  \n",
       "510     23.0  321.00  45.00  24.0  \n",
       "\n",
       "[511 rows x 14 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1005629b",
   "metadata": {},
   "source": [
    "## Column description\n",
    "\n",
    "1. **CRIM** - per capita crime rate by town\n",
    "2. **ZN** - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "3. **INDUS** - proportion of non-retail business acres per town\n",
    "4. **CHAS** - Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "5. **NOX** - nitric oxides concentration (parts per 10 million)\n",
    "6. **RM** - average number of rooms per dwelling\n",
    "7. **AGE** - proportion of owner-occupied units built prior to 1940\n",
    "8. **DIS** - weighted distances to five Boston employment centres\n",
    "9. **RAD** - index of accessibility to radial highways\n",
    "10. **TAX** - full-value property-tax rate per \\$10,000\n",
    "\n",
    "11. **PTRATIO** - pupil-teacher ratio by town\n",
    "12. **B** - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks\n",
    "by town\n",
    "13. **LSTAT** -  % lower status of the population\n",
    "14. **MEDV** - Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0f4e986d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         5\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "28c62009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>511.0</td>\n",
       "      <td>3.584139</td>\n",
       "      <td>8.564433</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>0.082325</td>\n",
       "      <td>0.26169</td>\n",
       "      <td>3.621175</td>\n",
       "      <td>88.9762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>511.0</td>\n",
       "      <td>11.252446</td>\n",
       "      <td>23.234838</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>511.0</td>\n",
       "      <td>11.151096</td>\n",
       "      <td>6.828175</td>\n",
       "      <td>0.46000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>9.69000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>27.7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>511.0</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.252838</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>511.0</td>\n",
       "      <td>0.554757</td>\n",
       "      <td>0.115310</td>\n",
       "      <td>0.38500</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>0.53800</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.8710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>506.0</td>\n",
       "      <td>6.287589</td>\n",
       "      <td>0.703802</td>\n",
       "      <td>3.56100</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>6.20900</td>\n",
       "      <td>6.629750</td>\n",
       "      <td>8.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>511.0</td>\n",
       "      <td>68.616243</td>\n",
       "      <td>28.099130</td>\n",
       "      <td>2.90000</td>\n",
       "      <td>45.050000</td>\n",
       "      <td>77.30000</td>\n",
       "      <td>94.050000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>511.0</td>\n",
       "      <td>3.783876</td>\n",
       "      <td>2.098631</td>\n",
       "      <td>1.12960</td>\n",
       "      <td>2.100350</td>\n",
       "      <td>3.15230</td>\n",
       "      <td>5.118000</td>\n",
       "      <td>12.1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>511.0</td>\n",
       "      <td>9.485323</td>\n",
       "      <td>8.688469</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>511.0</td>\n",
       "      <td>407.440313</td>\n",
       "      <td>167.903532</td>\n",
       "      <td>187.00000</td>\n",
       "      <td>279.500000</td>\n",
       "      <td>330.00000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>711.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>511.0</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>2.200348</td>\n",
       "      <td>12.60000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>19.10000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>23.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>511.0</td>\n",
       "      <td>356.600900</td>\n",
       "      <td>90.882679</td>\n",
       "      <td>0.32000</td>\n",
       "      <td>374.710000</td>\n",
       "      <td>391.34000</td>\n",
       "      <td>396.210000</td>\n",
       "      <td>396.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>511.0</td>\n",
       "      <td>12.879550</td>\n",
       "      <td>7.797416</td>\n",
       "      <td>1.73000</td>\n",
       "      <td>7.065000</td>\n",
       "      <td>11.45000</td>\n",
       "      <td>17.105000</td>\n",
       "      <td>76.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEDV</th>\n",
       "      <td>511.0</td>\n",
       "      <td>22.682192</td>\n",
       "      <td>9.484262</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>17.050000</td>\n",
       "      <td>21.20000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>67.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count        mean         std        min         25%        50%  \\\n",
       "CRIM     511.0    3.584139    8.564433    0.00632    0.082325    0.26169   \n",
       "ZN       511.0   11.252446   23.234838    0.00000    0.000000    0.00000   \n",
       "INDUS    511.0   11.151096    6.828175    0.46000    5.190000    9.69000   \n",
       "CHAS     511.0    0.068493    0.252838    0.00000    0.000000    0.00000   \n",
       "NOX      511.0    0.554757    0.115310    0.38500    0.449000    0.53800   \n",
       "RM       506.0    6.287589    0.703802    3.56100    5.885500    6.20900   \n",
       "AGE      511.0   68.616243   28.099130    2.90000   45.050000   77.30000   \n",
       "DIS      511.0    3.783876    2.098631    1.12960    2.100350    3.15230   \n",
       "RAD      511.0    9.485323    8.688469    1.00000    4.000000    5.00000   \n",
       "TAX      511.0  407.440313  167.903532  187.00000  279.500000  330.00000   \n",
       "PTRATIO  511.0   18.500000    2.200348   12.60000   17.400000   19.10000   \n",
       "B        511.0  356.600900   90.882679    0.32000  374.710000  391.34000   \n",
       "LSTAT    511.0   12.879550    7.797416    1.73000    7.065000   11.45000   \n",
       "MEDV     511.0   22.682192    9.484262    5.00000   17.050000   21.20000   \n",
       "\n",
       "                75%       max  \n",
       "CRIM       3.621175   88.9762  \n",
       "ZN        12.500000  100.0000  \n",
       "INDUS     18.100000   27.7400  \n",
       "CHAS       0.000000    1.0000  \n",
       "NOX        0.624000    0.8710  \n",
       "RM         6.629750    8.7800  \n",
       "AGE       94.050000  100.0000  \n",
       "DIS        5.118000   12.1265  \n",
       "RAD       24.000000   24.0000  \n",
       "TAX      666.000000  711.0000  \n",
       "PTRATIO   20.200000   23.0000  \n",
       "B        396.210000  396.9000  \n",
       "LSTAT     17.105000   76.0000  \n",
       "MEDV      25.000000   67.0000  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a1e5ec",
   "metadata": {},
   "source": [
    "We can see that RM has 5 null values, we will fill that value with the mean of the columns RM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "42e4b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2e0fca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.MEDV\n",
    "data = data.drop(columns=['MEDV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f9de9d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_value = data['RM'].mean()\n",
    " \n",
    "data['RM'].fillna(value=mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "10abe386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>511.0</td>\n",
       "      <td>3.584139</td>\n",
       "      <td>8.564433</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>0.082325</td>\n",
       "      <td>0.26169</td>\n",
       "      <td>3.621175</td>\n",
       "      <td>88.9762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>511.0</td>\n",
       "      <td>11.252446</td>\n",
       "      <td>23.234838</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>511.0</td>\n",
       "      <td>11.151096</td>\n",
       "      <td>6.828175</td>\n",
       "      <td>0.46000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>9.69000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>27.7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>511.0</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.252838</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>511.0</td>\n",
       "      <td>0.554757</td>\n",
       "      <td>0.115310</td>\n",
       "      <td>0.38500</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>0.53800</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.8710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>511.0</td>\n",
       "      <td>6.287589</td>\n",
       "      <td>0.700343</td>\n",
       "      <td>3.56100</td>\n",
       "      <td>5.887500</td>\n",
       "      <td>6.21100</td>\n",
       "      <td>6.627000</td>\n",
       "      <td>8.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>511.0</td>\n",
       "      <td>68.616243</td>\n",
       "      <td>28.099130</td>\n",
       "      <td>2.90000</td>\n",
       "      <td>45.050000</td>\n",
       "      <td>77.30000</td>\n",
       "      <td>94.050000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>511.0</td>\n",
       "      <td>3.783876</td>\n",
       "      <td>2.098631</td>\n",
       "      <td>1.12960</td>\n",
       "      <td>2.100350</td>\n",
       "      <td>3.15230</td>\n",
       "      <td>5.118000</td>\n",
       "      <td>12.1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>511.0</td>\n",
       "      <td>9.485323</td>\n",
       "      <td>8.688469</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>511.0</td>\n",
       "      <td>407.440313</td>\n",
       "      <td>167.903532</td>\n",
       "      <td>187.00000</td>\n",
       "      <td>279.500000</td>\n",
       "      <td>330.00000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>711.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>511.0</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>2.200348</td>\n",
       "      <td>12.60000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>19.10000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>23.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>511.0</td>\n",
       "      <td>356.600900</td>\n",
       "      <td>90.882679</td>\n",
       "      <td>0.32000</td>\n",
       "      <td>374.710000</td>\n",
       "      <td>391.34000</td>\n",
       "      <td>396.210000</td>\n",
       "      <td>396.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>511.0</td>\n",
       "      <td>12.879550</td>\n",
       "      <td>7.797416</td>\n",
       "      <td>1.73000</td>\n",
       "      <td>7.065000</td>\n",
       "      <td>11.45000</td>\n",
       "      <td>17.105000</td>\n",
       "      <td>76.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count        mean         std        min         25%        50%  \\\n",
       "CRIM     511.0    3.584139    8.564433    0.00632    0.082325    0.26169   \n",
       "ZN       511.0   11.252446   23.234838    0.00000    0.000000    0.00000   \n",
       "INDUS    511.0   11.151096    6.828175    0.46000    5.190000    9.69000   \n",
       "CHAS     511.0    0.068493    0.252838    0.00000    0.000000    0.00000   \n",
       "NOX      511.0    0.554757    0.115310    0.38500    0.449000    0.53800   \n",
       "RM       511.0    6.287589    0.700343    3.56100    5.887500    6.21100   \n",
       "AGE      511.0   68.616243   28.099130    2.90000   45.050000   77.30000   \n",
       "DIS      511.0    3.783876    2.098631    1.12960    2.100350    3.15230   \n",
       "RAD      511.0    9.485323    8.688469    1.00000    4.000000    5.00000   \n",
       "TAX      511.0  407.440313  167.903532  187.00000  279.500000  330.00000   \n",
       "PTRATIO  511.0   18.500000    2.200348   12.60000   17.400000   19.10000   \n",
       "B        511.0  356.600900   90.882679    0.32000  374.710000  391.34000   \n",
       "LSTAT    511.0   12.879550    7.797416    1.73000    7.065000   11.45000   \n",
       "\n",
       "                75%       max  \n",
       "CRIM       3.621175   88.9762  \n",
       "ZN        12.500000  100.0000  \n",
       "INDUS     18.100000   27.7400  \n",
       "CHAS       0.000000    1.0000  \n",
       "NOX        0.624000    0.8710  \n",
       "RM         6.627000    8.7800  \n",
       "AGE       94.050000  100.0000  \n",
       "DIS        5.118000   12.1265  \n",
       "RAD       24.000000   24.0000  \n",
       "TAX      666.000000  711.0000  \n",
       "PTRATIO   20.200000   23.0000  \n",
       "B        396.210000  396.9000  \n",
       "LSTAT     17.105000   76.0000  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a96b9007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "data = min_max_scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4dc3edd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.80000000e-01, 6.78152493e-02, ...,\n",
       "        2.59615385e-01, 1.00000000e+00, 4.37592568e-02],\n",
       "       [2.35922539e-04, 0.00000000e+00, 2.42302053e-01, ...,\n",
       "        5.00000000e-01, 1.00000000e+00, 9.97711054e-02],\n",
       "       [2.35697744e-04, 0.00000000e+00, 2.42302053e-01, ...,\n",
       "        5.00000000e-01, 9.89737254e-01, 3.09680894e-02],\n",
       "       ...,\n",
       "       [4.92312679e-03, 0.00000000e+00, 4.41348974e-01, ...,\n",
       "        1.00000000e+00, 8.64087952e-01, 2.59458732e-01],\n",
       "       [8.66933843e-03, 0.00000000e+00, 4.48680352e-01, ...,\n",
       "        1.00000000e+00, 8.64087952e-01, 1.00000000e+00],\n",
       "       [7.28336376e-03, 0.00000000e+00, 4.52346041e-01, ...,\n",
       "        1.00000000e+00, 8.08613647e-01, 5.82604012e-01]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963880ba",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0d687a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "65a48a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "590c8d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511, 13)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b31cbcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.80000000e-01, 6.78152493e-02, 0.00000000e+00,\n",
       "        3.14814815e-01, 5.77505269e-01, 6.41606591e-01, 2.69203139e-01,\n",
       "        0.00000000e+00, 2.08015267e-01, 2.59615385e-01, 1.00000000e+00,\n",
       "        4.37592568e-02],\n",
       "       [2.35922539e-04, 0.00000000e+00, 2.42302053e-01, 0.00000000e+00,\n",
       "        1.72839506e-01, 5.47997701e-01, 7.82698249e-01, 3.48961980e-01,\n",
       "        4.34782609e-02, 1.04961832e-01, 5.00000000e-01, 1.00000000e+00,\n",
       "        9.97711054e-02],\n",
       "       [2.35697744e-04, 0.00000000e+00, 2.42302053e-01, 0.00000000e+00,\n",
       "        1.72839506e-01, 6.94385898e-01, 5.99382080e-01, 3.48961980e-01,\n",
       "        4.34782609e-02, 1.04961832e-01, 5.00000000e-01, 9.89737254e-01,\n",
       "        3.09680894e-02],\n",
       "       [2.92795719e-04, 0.00000000e+00, 6.30498534e-02, 0.00000000e+00,\n",
       "        1.50205761e-01, 6.58555279e-01, 4.41812564e-01, 4.48544590e-01,\n",
       "        8.69565217e-02, 6.67938931e-02, 5.86538462e-01, 9.94276060e-01,\n",
       "        1.62919079e-02],\n",
       "       [7.05070075e-04, 0.00000000e+00, 6.30498534e-02, 0.00000000e+00,\n",
       "        1.50205761e-01, 6.87104809e-01, 5.28321318e-01, 4.48544590e-01,\n",
       "        8.69565217e-02, 6.67938931e-02, 5.86538462e-01, 1.00000000e+00,\n",
       "        4.84717921e-02],\n",
       "       [2.64471527e-04, 0.00000000e+00, 6.30498534e-02, 0.00000000e+00,\n",
       "        1.50205761e-01, 5.49722169e-01, 5.74665294e-01, 4.48544590e-01,\n",
       "        8.69565217e-02, 6.67938931e-02, 5.86538462e-01, 9.92990065e-01,\n",
       "        4.68560657e-02],\n",
       "       [9.21323037e-04, 1.25000000e-01, 2.71627566e-01, 0.00000000e+00,\n",
       "        2.86008230e-01, 4.69630197e-01, 6.56024717e-01, 4.02922642e-01,\n",
       "        1.73913043e-01, 2.36641221e-01, 2.50000000e-01, 9.96721973e-01,\n",
       "        1.44068938e-01],\n",
       "       [1.55367187e-03, 1.25000000e-01, 2.71627566e-01, 0.00000000e+00,\n",
       "        2.86008230e-01, 5.00287411e-01, 9.59835221e-01, 4.38387182e-01,\n",
       "        1.73913043e-01, 2.36641221e-01, 2.50000000e-01, 1.00000000e+00,\n",
       "        2.34549616e-01],\n",
       "       [2.30325139e-03, 1.25000000e-01, 2.71627566e-01, 0.00000000e+00,\n",
       "        2.86008230e-01, 3.96627706e-01, 1.00000000e+00, 4.50354191e-01,\n",
       "        1.73913043e-01, 2.36641221e-01, 2.50000000e-01, 9.74103586e-01,\n",
       "        3.79695705e-01],\n",
       "       [1.84017333e-03, 1.25000000e-01, 2.71627566e-01, 0.00000000e+00,\n",
       "        2.86008230e-01, 4.68097337e-01, 8.54788877e-01, 4.96730897e-01,\n",
       "        1.73913043e-01, 2.36641221e-01, 2.50000000e-01, 9.74305310e-01,\n",
       "        2.06947624e-01]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "035b7270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "67729cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(13, )))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d5dd5fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_135 (Dense)           (None, 64)                896       \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 8)                 520       \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5617 (21.94 KB)\n",
      "Trainable params: 5617 (21.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2ab23a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 1s 15ms/step - loss: 683.7951 - val_loss: 374.5387\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 659.1937 - val_loss: 347.3034\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 617.0784 - val_loss: 297.3370\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 541.5710 - val_loss: 216.6890\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 412.9204 - val_loss: 119.5989\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 238.5058 - val_loss: 127.3781\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 107.3201 - val_loss: 391.6622\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 92.6267 - val_loss: 416.8553\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 84.9962 - val_loss: 297.1216\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 78.6310 - val_loss: 262.9685\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 75.2604 - val_loss: 270.0916\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 71.6786 - val_loss: 239.5932\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 68.5278 - val_loss: 234.4408\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 66.5971 - val_loss: 246.9253\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 63.6744 - val_loss: 192.1170\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 60.3028 - val_loss: 182.2060\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 57.6874 - val_loss: 170.2270\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 54.7554 - val_loss: 161.9040\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 52.0190 - val_loss: 151.3445\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 49.0421 - val_loss: 133.1820\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 46.7130 - val_loss: 122.9112\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 44.2665 - val_loss: 127.3731\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 40.9946 - val_loss: 106.9251\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 37.8945 - val_loss: 98.5482\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 34.7914 - val_loss: 95.1661\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 31.8265 - val_loss: 89.9220\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 28.7392 - val_loss: 86.8559\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 25.8447 - val_loss: 85.6969\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 23.2741 - val_loss: 83.6159\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 20.9002 - val_loss: 84.2295\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 18.7538 - val_loss: 85.2253\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 17.1541 - val_loss: 86.2810\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 15.7612 - val_loss: 88.1719\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 15.1189 - val_loss: 88.1270\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 14.2786 - val_loss: 90.3465\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 13.3978 - val_loss: 92.4089\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 12.8380 - val_loss: 90.3299\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 12.5080 - val_loss: 92.2508\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 11.9319 - val_loss: 91.0964\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 11.5708 - val_loss: 92.3520\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 11.4599 - val_loss: 92.9165\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 11.1261 - val_loss: 93.2895\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.8767 - val_loss: 93.1545\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.7565 - val_loss: 93.1284\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.6908 - val_loss: 92.6254\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.4612 - val_loss: 92.8593\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.3366 - val_loss: 92.8219\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.1564 - val_loss: 93.0173\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.6922 - val_loss: 94.6161\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.3504 - val_loss: 93.8414\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 10.0100 - val_loss: 93.6924\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.8705 - val_loss: 93.6571\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.6819 - val_loss: 94.0730\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.4837 - val_loss: 93.4841\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9.6362 - val_loss: 93.9716\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 9.3503 - val_loss: 93.8277\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.3496 - val_loss: 94.2961\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.1140 - val_loss: 93.7206\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.2359 - val_loss: 93.8547\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.0049 - val_loss: 93.7304\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.1944 - val_loss: 94.4374\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 9.3240 - val_loss: 94.1578\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.7552 - val_loss: 94.3128\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.6784 - val_loss: 94.5545\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.7879 - val_loss: 94.8260\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.7411 - val_loss: 94.8845\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.5028 - val_loss: 94.9809\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.4611 - val_loss: 95.1623\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.5389 - val_loss: 94.9083\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.7343 - val_loss: 95.3142\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.5202 - val_loss: 94.2533\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.2749 - val_loss: 94.3323\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.2743 - val_loss: 94.3727\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.2137 - val_loss: 94.5537\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.1819 - val_loss: 97.1902\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.6524 - val_loss: 95.4893\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.4308 - val_loss: 95.8142\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.0171 - val_loss: 96.5952\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.0613 - val_loss: 96.2413\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.1565 - val_loss: 96.1269\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 5ms/step - loss: 8.1433 - val_loss: 97.3161\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.3514 - val_loss: 98.9693\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.2800 - val_loss: 98.7457\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.8206 - val_loss: 96.6614\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.7444 - val_loss: 97.7133\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.8327 - val_loss: 97.4965\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.7265 - val_loss: 98.5481\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.8956 - val_loss: 97.4739\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.7042 - val_loss: 99.1090\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.7012 - val_loss: 99.7198\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.6385 - val_loss: 98.0352\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.4980 - val_loss: 98.1780\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.4541 - val_loss: 98.0678\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.4524 - val_loss: 100.0250\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.4385 - val_loss: 99.5174\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.4287 - val_loss: 100.4070\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.3891 - val_loss: 99.3398\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7.4470 - val_loss: 97.7366\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.3400 - val_loss: 101.1161\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.4327 - val_loss: 101.7446\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8.5587 - val_loss: 98.0342\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 8.0044 - val_loss: 99.1699\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.4962 - val_loss: 99.9604\n",
      "Epoch 104/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.3061 - val_loss: 102.2335\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.2981 - val_loss: 97.8875\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.1442 - val_loss: 101.3182\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7.0937 - val_loss: 97.9022\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.0924 - val_loss: 100.1621\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.2306 - val_loss: 100.8664\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.1528 - val_loss: 100.4225\n",
      "Epoch 111/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.9793 - val_loss: 98.6120\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.0383 - val_loss: 101.7573\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.9955 - val_loss: 98.8269\n",
      "Epoch 114/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.8701 - val_loss: 100.6949\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.8739 - val_loss: 101.3756\n",
      "Epoch 116/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.9299 - val_loss: 98.7406\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.9427 - val_loss: 100.0087\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.8639 - val_loss: 102.9935\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.8876 - val_loss: 98.7942\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.7774 - val_loss: 100.7615\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.8455 - val_loss: 105.3893\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.0347 - val_loss: 98.0583\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 7.0055 - val_loss: 101.5356\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.6415 - val_loss: 101.0165\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.5619 - val_loss: 101.3102\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.7585 - val_loss: 99.1239\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.4981 - val_loss: 101.5580\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.8641 - val_loss: 99.5459\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.4989 - val_loss: 100.2562\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.4156 - val_loss: 97.6339\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.8611 - val_loss: 99.6375\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.4751 - val_loss: 100.9895\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.3367 - val_loss: 103.2955\n",
      "Epoch 134/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.5045 - val_loss: 102.5748\n",
      "Epoch 135/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.7350 - val_loss: 99.9390\n",
      "Epoch 136/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.4235 - val_loss: 101.7292\n",
      "Epoch 137/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.2640 - val_loss: 102.2713\n",
      "Epoch 138/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.3804 - val_loss: 101.7429\n",
      "Epoch 139/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.2067 - val_loss: 102.3367\n",
      "Epoch 140/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.2356 - val_loss: 100.9497\n",
      "Epoch 141/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.3644 - val_loss: 98.9385\n",
      "Epoch 142/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.4453 - val_loss: 102.7535\n",
      "Epoch 143/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.1239 - val_loss: 102.9357\n",
      "Epoch 144/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.3647 - val_loss: 101.7319\n",
      "Epoch 145/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.6674 - val_loss: 99.8668\n",
      "Epoch 146/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.4011 - val_loss: 101.8978\n",
      "Epoch 147/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.3340 - val_loss: 104.3388\n",
      "Epoch 148/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.3126 - val_loss: 104.4384\n",
      "Epoch 149/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.1451 - val_loss: 100.3164\n",
      "Epoch 150/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.1623 - val_loss: 100.7643\n",
      "Epoch 151/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.9892 - val_loss: 103.2710\n",
      "Epoch 152/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.9396 - val_loss: 101.0351\n",
      "Epoch 153/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.1216 - val_loss: 105.4071\n",
      "Epoch 154/200\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 6.2730 - val_loss: 104.6524\n",
      "Epoch 155/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.9744 - val_loss: 101.3677\n",
      "Epoch 156/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.9971 - val_loss: 101.2160\n",
      "Epoch 157/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.0068 - val_loss: 102.5704\n",
      "Epoch 158/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.1114 - val_loss: 98.5842\n",
      "Epoch 159/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.9389 - val_loss: 102.5468\n",
      "Epoch 160/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.0621 - val_loss: 100.8192\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 5ms/step - loss: 5.9056 - val_loss: 98.5341\n",
      "Epoch 162/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.9096 - val_loss: 100.6276\n",
      "Epoch 163/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.1895 - val_loss: 103.6686\n",
      "Epoch 164/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6.2407 - val_loss: 103.6234\n",
      "Epoch 165/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 6.9110 - val_loss: 96.8230\n",
      "Epoch 166/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.9251 - val_loss: 99.4911\n",
      "Epoch 167/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.7981 - val_loss: 95.9571\n",
      "Epoch 168/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.9373 - val_loss: 99.7021\n",
      "Epoch 169/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.7488 - val_loss: 99.7680\n",
      "Epoch 170/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.8154 - val_loss: 101.1030\n",
      "Epoch 171/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.9743 - val_loss: 102.0310\n",
      "Epoch 172/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.8672 - val_loss: 96.5060\n",
      "Epoch 173/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.6692 - val_loss: 99.3953\n",
      "Epoch 174/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.7138 - val_loss: 100.9934\n",
      "Epoch 175/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.8395 - val_loss: 103.6064\n",
      "Epoch 176/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.7779 - val_loss: 97.1425\n",
      "Epoch 177/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.7633 - val_loss: 98.4935\n",
      "Epoch 178/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.6735 - val_loss: 100.6216\n",
      "Epoch 179/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.7051 - val_loss: 95.9164\n",
      "Epoch 180/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.7146 - val_loss: 100.1454\n",
      "Epoch 181/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.7448 - val_loss: 97.9593\n",
      "Epoch 182/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.8340 - val_loss: 95.6117\n",
      "Epoch 183/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.6411 - val_loss: 96.6390\n",
      "Epoch 184/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.6390 - val_loss: 102.8108\n",
      "Epoch 185/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.5518 - val_loss: 97.8560\n",
      "Epoch 186/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.4501 - val_loss: 101.2361\n",
      "Epoch 187/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.6504 - val_loss: 94.8402\n",
      "Epoch 188/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.7422 - val_loss: 97.3673\n",
      "Epoch 189/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.5282 - val_loss: 101.8127\n",
      "Epoch 190/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.4752 - val_loss: 99.7258\n",
      "Epoch 191/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.4943 - val_loss: 97.5259\n",
      "Epoch 192/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.4418 - val_loss: 99.1888\n",
      "Epoch 193/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.7541 - val_loss: 95.7308\n",
      "Epoch 194/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.9208 - val_loss: 102.5642\n",
      "Epoch 195/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.5956 - val_loss: 98.9456\n",
      "Epoch 196/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.6412 - val_loss: 94.5016\n",
      "Epoch 197/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5.9484 - val_loss: 94.1018\n",
      "Epoch 198/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.5298 - val_loss: 103.2607\n",
      "Epoch 199/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.6086 - val_loss: 95.9014\n",
      "Epoch 200/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 5.4589 - val_loss: 95.0173\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, batch_size=32, epochs=200, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8988b72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[30.471714]], dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[3].reshape(1,13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b687ab49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.4"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c538873c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f7f8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
