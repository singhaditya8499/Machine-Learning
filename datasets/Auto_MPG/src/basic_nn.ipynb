{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09dd3bc6",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d615309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f820e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "data = pd.read_csv(\"../data/auto-mpg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "756c4603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0   \n",
       "1  15.0          8         350.0       165.0    3693          11.5   \n",
       "2  18.0          8         318.0       150.0    3436          11.0   \n",
       "3  16.0          8         304.0       150.0    3433          12.0   \n",
       "4  17.0          8         302.0       140.0    3449          10.5   \n",
       "\n",
       "   model year  origin                   car name  \n",
       "0          70       1  chevrolet chevelle malibu  \n",
       "1          70       1          buick skylark 320  \n",
       "2          70       1         plymouth satellite  \n",
       "3          70       1              amc rebel sst  \n",
       "4          70       1                ford torino  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peeking the dataset\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31bcdcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
       "       'acceleration', 'model year', 'origin', 'car name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetching the column details\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58f1c4b",
   "metadata": {},
   "source": [
    "1. **mpg (Miles Per Gallon):**\n",
    "   - This column represents the fuel efficiency of the car, measured in miles per gallon. It indicates how far the car can travel on one gallon of fuel.\n",
    "\n",
    "2. **cylinders:**\n",
    "   - The number of cylinders in the engine of the car. Cars can have different cylinder configurations, such as 4, 6, or 8 cylinders.\n",
    "\n",
    "3. **displacement:**\n",
    "   - The engine displacement is the total volume of all the cylinders in the engine. It is usually measured in cubic inches or cubic centimeters. Larger displacements generally indicate more powerful engines.\n",
    "\n",
    "4. **horsepower:**\n",
    "   - The measure of the engine's power. It represents the rate at which work is done by the engine. Higher horsepower values generally indicate more powerful engines.\n",
    "\n",
    "5. **weight:**\n",
    "   - The weight of the car, often measured in pounds or kilograms. This is the total mass of the vehicle.\n",
    "\n",
    "6. **acceleration:**\n",
    "   - The time it takes for the car to accelerate from 0 to 60 miles per hour. It is a measure of the car's performance in terms of acceleration.\n",
    "\n",
    "7. **model year:**\n",
    "   - The year in which the car model was manufactured.\n",
    "\n",
    "8. **origin:**\n",
    "   - This column might represent the country or region of origin for the car. It could be encoded numerically, where different numbers represent different regions.\n",
    "\n",
    "9. **car name:**\n",
    "   - The name or identifier of the car model. This column contains the individual names of each car in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90796c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horsepower      0\n",
       "weight          0\n",
       "acceleration    0\n",
       "model year      0\n",
       "origin          0\n",
       "car name        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71d2c01",
   "metadata": {},
   "source": [
    "There is no NA or NULL values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25fb1ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             float64\n",
       "cylinders         int64\n",
       "displacement    float64\n",
       "horsepower       object\n",
       "weight            int64\n",
       "acceleration    float64\n",
       "model year        int64\n",
       "origin            int64\n",
       "car name         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b01fe1",
   "metadata": {},
   "source": [
    "This suggest that `horsepower` should be a number but it is object probably because of non-numeric characters. On further deep dive we find that 6 entries have `?` as the horsepower. We will fill it with the mean value of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "183d9094",
   "metadata": {},
   "outputs": [],
   "source": [
    "horsepower_mean = 0.0\n",
    "data_temp = data[data[\"horsepower\"] != '?']\n",
    "data_temp[\"horsepower\"] = pd.to_numeric(data_temp[\"horsepower\"])\n",
    "horsepower_mean = data_temp.horsepower.mean()\n",
    "def updateHorsepower(x):\n",
    "    if x == '?':\n",
    "        x = horsepower_mean\n",
    "    return float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5d2145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.horsepower = data.horsepower.apply(updateHorsepower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d991cee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mpg</th>\n",
       "      <td>398.0</td>\n",
       "      <td>23.514573</td>\n",
       "      <td>7.815984</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.500</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.000</td>\n",
       "      <td>46.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>398.0</td>\n",
       "      <td>5.454774</td>\n",
       "      <td>1.701004</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>398.0</td>\n",
       "      <td>193.425879</td>\n",
       "      <td>104.269838</td>\n",
       "      <td>68.0</td>\n",
       "      <td>104.250</td>\n",
       "      <td>148.5</td>\n",
       "      <td>262.000</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>398.0</td>\n",
       "      <td>104.469388</td>\n",
       "      <td>38.199187</td>\n",
       "      <td>46.0</td>\n",
       "      <td>76.000</td>\n",
       "      <td>95.0</td>\n",
       "      <td>125.000</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>398.0</td>\n",
       "      <td>2970.424623</td>\n",
       "      <td>846.841774</td>\n",
       "      <td>1613.0</td>\n",
       "      <td>2223.750</td>\n",
       "      <td>2803.5</td>\n",
       "      <td>3608.000</td>\n",
       "      <td>5140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>398.0</td>\n",
       "      <td>15.568090</td>\n",
       "      <td>2.757689</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.825</td>\n",
       "      <td>15.5</td>\n",
       "      <td>17.175</td>\n",
       "      <td>24.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model year</th>\n",
       "      <td>398.0</td>\n",
       "      <td>76.010050</td>\n",
       "      <td>3.697627</td>\n",
       "      <td>70.0</td>\n",
       "      <td>73.000</td>\n",
       "      <td>76.0</td>\n",
       "      <td>79.000</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <td>398.0</td>\n",
       "      <td>1.572864</td>\n",
       "      <td>0.802055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count         mean         std     min       25%     50%  \\\n",
       "mpg           398.0    23.514573    7.815984     9.0    17.500    23.0   \n",
       "cylinders     398.0     5.454774    1.701004     3.0     4.000     4.0   \n",
       "displacement  398.0   193.425879  104.269838    68.0   104.250   148.5   \n",
       "horsepower    398.0   104.469388   38.199187    46.0    76.000    95.0   \n",
       "weight        398.0  2970.424623  846.841774  1613.0  2223.750  2803.5   \n",
       "acceleration  398.0    15.568090    2.757689     8.0    13.825    15.5   \n",
       "model year    398.0    76.010050    3.697627    70.0    73.000    76.0   \n",
       "origin        398.0     1.572864    0.802055     1.0     1.000     1.0   \n",
       "\n",
       "                   75%     max  \n",
       "mpg             29.000    46.6  \n",
       "cylinders        8.000     8.0  \n",
       "displacement   262.000   455.0  \n",
       "horsepower     125.000   230.0  \n",
       "weight        3608.000  5140.0  \n",
       "acceleration    17.175    24.8  \n",
       "model year      79.000    82.0  \n",
       "origin           2.000     3.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describing the dataset columns\n",
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4757efec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    249\n",
       "3     79\n",
       "2     70\n",
       "Name: origin, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# origin should not have any major impact on the result, but we are still going to take it in input\n",
    "data.origin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4e165db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ford pinto             6\n",
       "toyota corolla         5\n",
       "amc matador            5\n",
       "ford maverick          5\n",
       "chevrolet chevette     4\n",
       "                      ..\n",
       "chevrolet monza 2+2    1\n",
       "ford mustang ii        1\n",
       "pontiac astro          1\n",
       "amc pacer              1\n",
       "chevy s-10             1\n",
       "Name: car name, Length: 305, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['car name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a86ede8",
   "metadata": {},
   "source": [
    "`Car name` is not important and we can drop it from the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb16f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['car name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5329be29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
       "       'acceleration', 'model year', 'origin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5457eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalising the dataset using min-max normalising\n",
    "data_norm = (data - data.min())/(data.max() - data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8877b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.617571</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.536150</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.159574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.646739</td>\n",
       "      <td>0.589736</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.239362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.645995</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.516870</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.186170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.609819</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.516019</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.212766</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.510870</td>\n",
       "      <td>0.520556</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mpg  cylinders  displacement  horsepower    weight  acceleration  \\\n",
       "0  0.239362        1.0      0.617571    0.456522  0.536150      0.238095   \n",
       "1  0.159574        1.0      0.728682    0.646739  0.589736      0.208333   \n",
       "2  0.239362        1.0      0.645995    0.565217  0.516870      0.178571   \n",
       "3  0.186170        1.0      0.609819    0.565217  0.516019      0.238095   \n",
       "4  0.212766        1.0      0.604651    0.510870  0.520556      0.148810   \n",
       "\n",
       "   model year  origin  \n",
       "0         0.0     0.0  \n",
       "1         0.0     0.0  \n",
       "2         0.0     0.0  \n",
       "3         0.0     0.0  \n",
       "4         0.0     0.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b3f6c9",
   "metadata": {},
   "source": [
    "#### Splitting the dataset into train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b62daf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9436278",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_norm.mpg\n",
    "X = data_norm.drop(columns=['mpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bc6d82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "44aca22a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075853c0",
   "metadata": {},
   "source": [
    "### Building the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0b70525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5c064b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(hiddenLayers=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(7, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1079f5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_51 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 32)                256       \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1025 (4.00 KB)\n",
      "Trainable params: 1025 (4.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = getModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "77c847c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "16/16 [==============================] - 1s 21ms/step - loss: 0.1733 - val_loss: 0.1825\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1445 - val_loss: 0.1459\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1047 - val_loss: 0.0917\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0541 - val_loss: 0.0386\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0315 - val_loss: 0.0263\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0209\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0156\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0121\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0092\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0090\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0088\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0084\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0075\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0074\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0074\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0069\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0066\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0065\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0062\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 83/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0055\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0045\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=300, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c50778cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783220d5",
   "metadata": {},
   "source": [
    "Looking at the loss, we are going with 100 epochs for the same neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "014c14ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 1s 11ms/step - loss: 0.0483 - val_loss: 0.0164\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0126\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0088\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0084\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0075\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0066\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0064\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0065\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0061\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0061\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fabad52dd60>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final = getModel()\n",
    "model_final.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "20811164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "07d81959",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'truth': y_test, 'prediction': np.reshape(prediction, (80,))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1aa36f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truth</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.436170</td>\n",
       "      <td>0.397992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.661841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.186170</td>\n",
       "      <td>0.200725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.335106</td>\n",
       "      <td>0.416222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.525405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.585106</td>\n",
       "      <td>0.769024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.271277</td>\n",
       "      <td>0.268031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.132979</td>\n",
       "      <td>0.117766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.398936</td>\n",
       "      <td>0.465811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.372264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        truth  prediction\n",
       "361  0.436170    0.397992\n",
       "198  0.638298    0.661841\n",
       "161  0.186170    0.200725\n",
       "276  0.335106    0.416222\n",
       "318  0.553191    0.525405\n",
       "..        ...         ...\n",
       "377  0.585106    0.769024\n",
       "252  0.271277    0.268031\n",
       "6    0.132979    0.117766\n",
       "147  0.398936    0.465811\n",
       "109  0.319149    0.372264\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d6255959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss is:  0.00999675223547127\n"
     ]
    }
   ],
   "source": [
    "loss = sum((result.truth-result.prediction)**2)/X_test.shape[0]\n",
    "print(\"Final loss is: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847599fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
