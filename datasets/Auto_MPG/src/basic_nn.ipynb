{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d615309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f820e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/auto-mpg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "756c4603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0   \n",
       "1  15.0          8         350.0       165.0    3693          11.5   \n",
       "2  18.0          8         318.0       150.0    3436          11.0   \n",
       "3  16.0          8         304.0       150.0    3433          12.0   \n",
       "4  17.0          8         302.0       140.0    3449          10.5   \n",
       "\n",
       "   model year  origin                   car name  \n",
       "0          70       1  chevrolet chevelle malibu  \n",
       "1          70       1          buick skylark 320  \n",
       "2          70       1         plymouth satellite  \n",
       "3          70       1              amc rebel sst  \n",
       "4          70       1                ford torino  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42e78626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
       "       'acceleration', 'model year', 'origin', 'car name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90796c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horsepower      0\n",
       "weight          0\n",
       "acceleration    0\n",
       "model year      0\n",
       "origin          0\n",
       "car name        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25fb1ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             float64\n",
       "cylinders         int64\n",
       "displacement    float64\n",
       "horsepower       object\n",
       "weight            int64\n",
       "acceleration    float64\n",
       "model year        int64\n",
       "origin            int64\n",
       "car name         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d686c62",
   "metadata": {},
   "source": [
    "Need to change the type of horsepower and carname from object to numbers so that they can be fed to the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82c0a522",
   "metadata": {},
   "outputs": [],
   "source": [
    "horsepower_mean = 0.0\n",
    "data_temp = data[data[\"horsepower\"] != '?']\n",
    "data_temp[\"horsepower\"] = pd.to_numeric(data_temp[\"horsepower\"])\n",
    "horsepower_mean = data_temp.horsepower.mean()\n",
    "def updateHorsepower(x):\n",
    "    if x == '?':\n",
    "        x = horsepower_mean\n",
    "    return float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64d3d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.horsepower = data.horsepower.apply(updateHorsepower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d991cee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mpg</th>\n",
       "      <td>398.0</td>\n",
       "      <td>23.514573</td>\n",
       "      <td>7.815984</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.500</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.000</td>\n",
       "      <td>46.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>398.0</td>\n",
       "      <td>5.454774</td>\n",
       "      <td>1.701004</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>displacement</th>\n",
       "      <td>398.0</td>\n",
       "      <td>193.425879</td>\n",
       "      <td>104.269838</td>\n",
       "      <td>68.0</td>\n",
       "      <td>104.250</td>\n",
       "      <td>148.5</td>\n",
       "      <td>262.000</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horsepower</th>\n",
       "      <td>398.0</td>\n",
       "      <td>104.469388</td>\n",
       "      <td>38.199187</td>\n",
       "      <td>46.0</td>\n",
       "      <td>76.000</td>\n",
       "      <td>95.0</td>\n",
       "      <td>125.000</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>398.0</td>\n",
       "      <td>2970.424623</td>\n",
       "      <td>846.841774</td>\n",
       "      <td>1613.0</td>\n",
       "      <td>2223.750</td>\n",
       "      <td>2803.5</td>\n",
       "      <td>3608.000</td>\n",
       "      <td>5140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acceleration</th>\n",
       "      <td>398.0</td>\n",
       "      <td>15.568090</td>\n",
       "      <td>2.757689</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.825</td>\n",
       "      <td>15.5</td>\n",
       "      <td>17.175</td>\n",
       "      <td>24.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model year</th>\n",
       "      <td>398.0</td>\n",
       "      <td>76.010050</td>\n",
       "      <td>3.697627</td>\n",
       "      <td>70.0</td>\n",
       "      <td>73.000</td>\n",
       "      <td>76.0</td>\n",
       "      <td>79.000</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <td>398.0</td>\n",
       "      <td>1.572864</td>\n",
       "      <td>0.802055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count         mean         std     min       25%     50%  \\\n",
       "mpg           398.0    23.514573    7.815984     9.0    17.500    23.0   \n",
       "cylinders     398.0     5.454774    1.701004     3.0     4.000     4.0   \n",
       "displacement  398.0   193.425879  104.269838    68.0   104.250   148.5   \n",
       "horsepower    398.0   104.469388   38.199187    46.0    76.000    95.0   \n",
       "weight        398.0  2970.424623  846.841774  1613.0  2223.750  2803.5   \n",
       "acceleration  398.0    15.568090    2.757689     8.0    13.825    15.5   \n",
       "model year    398.0    76.010050    3.697627    70.0    73.000    76.0   \n",
       "origin        398.0     1.572864    0.802055     1.0     1.000     1.0   \n",
       "\n",
       "                   75%     max  \n",
       "mpg             29.000    46.6  \n",
       "cylinders        8.000     8.0  \n",
       "displacement   262.000   455.0  \n",
       "horsepower     125.000   230.0  \n",
       "weight        3608.000  5140.0  \n",
       "acceleration    17.175    24.8  \n",
       "model year      79.000    82.0  \n",
       "origin           2.000     3.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4757efec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    249\n",
       "3     79\n",
       "2     70\n",
       "Name: origin, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.origin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e85e31dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ford pinto             6\n",
       "toyota corolla         5\n",
       "amc matador            5\n",
       "ford maverick          5\n",
       "chevrolet chevette     4\n",
       "                      ..\n",
       "chevrolet monza 2+2    1\n",
       "ford mustang ii        1\n",
       "pontiac astro          1\n",
       "amc pacer              1\n",
       "chevy s-10             1\n",
       "Name: car name, Length: 305, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['car name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c524a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['car name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76b4d914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
       "       'acceleration', 'model year', 'origin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c954f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = (data - data.min())/(data.max() - data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3e8bead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.617571</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.536150</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.159574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.646739</td>\n",
       "      <td>0.589736</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.239362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.645995</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.516870</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.186170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.609819</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.516019</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.212766</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.510870</td>\n",
       "      <td>0.520556</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mpg  cylinders  displacement  horsepower    weight  acceleration  \\\n",
       "0  0.239362        1.0      0.617571    0.456522  0.536150      0.238095   \n",
       "1  0.159574        1.0      0.728682    0.646739  0.589736      0.208333   \n",
       "2  0.239362        1.0      0.645995    0.565217  0.516870      0.178571   \n",
       "3  0.186170        1.0      0.609819    0.565217  0.516019      0.238095   \n",
       "4  0.212766        1.0      0.604651    0.510870  0.520556      0.148810   \n",
       "\n",
       "   model year  origin  \n",
       "0         0.0     0.0  \n",
       "1         0.0     0.0  \n",
       "2         0.0     0.0  \n",
       "3         0.0     0.0  \n",
       "4         0.0     0.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "89c04f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b5979c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_norm.mpg\n",
    "X = data_norm.drop(columns=['mpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad733ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3f67e1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e1c252a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f9a80d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(hiddenLayers=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(7, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e58fd0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_51 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 32)                256       \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1025 (4.00 KB)\n",
      "Trainable params: 1025 (4.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = getModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "867c8576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "16/16 [==============================] - 1s 21ms/step - loss: 0.1733 - val_loss: 0.1825\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.1445 - val_loss: 0.1459\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1047 - val_loss: 0.0917\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0541 - val_loss: 0.0386\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0315 - val_loss: 0.0263\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0232 - val_loss: 0.0209\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0156\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0121\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0092\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0090\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0088\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0084\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0081\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0075\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0074\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0074\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0072\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0072\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0069\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0068\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0066\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0066\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 0.0065\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0062\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 83/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0054\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0055\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0052\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0050\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0050\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0049\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0050\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0051\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0050\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0050\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0049\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0047\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0027 - val_loss: 0.0045\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=300, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d8cb1f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ae1266",
   "metadata": {},
   "source": [
    "Looking at the loss, we are going with 100 epochs for the same neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7b065395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 1s 11ms/step - loss: 0.0483 - val_loss: 0.0164\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0126\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0117\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0088\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0084\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0079 - val_loss: 0.0083\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0080\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0075\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0076\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0066\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0064\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0080\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0060\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0060\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0050\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0065\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0047\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0051\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0059\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0061\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0061\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0042\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fabad52dd60>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final = getModel()\n",
    "model_final.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "90f50f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3094cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'truth': y_test, 'prediction': np.reshape(prediction, (80,))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4bb2c3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truth</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.436170</td>\n",
       "      <td>0.397992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.661841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.186170</td>\n",
       "      <td>0.200725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.335106</td>\n",
       "      <td>0.416222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.525405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.585106</td>\n",
       "      <td>0.769024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.271277</td>\n",
       "      <td>0.268031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.132979</td>\n",
       "      <td>0.117766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.398936</td>\n",
       "      <td>0.465811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.372264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        truth  prediction\n",
       "361  0.436170    0.397992\n",
       "198  0.638298    0.661841\n",
       "161  0.186170    0.200725\n",
       "276  0.335106    0.416222\n",
       "318  0.553191    0.525405\n",
       "..        ...         ...\n",
       "377  0.585106    0.769024\n",
       "252  0.271277    0.268031\n",
       "6    0.132979    0.117766\n",
       "147  0.398936    0.465811\n",
       "109  0.319149    0.372264\n",
       "\n",
       "[80 rows x 2 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d03b4759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss is:  0.00999675223547127\n"
     ]
    }
   ],
   "source": [
    "loss = sum((result.truth-result.prediction)**2)/X_test.shape[0]\n",
    "print(\"Final loss is: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dd8e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
